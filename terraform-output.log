An execution plan has been generated and is shown below.
Resource actions are indicated with the following symbols:
  + create
 <= read (data resources)

Terraform will perform the following actions:

  # module.eks_cluster.data.aws_availability_zones.available will be read during apply
  # (config refers to values not yet known)
 <= data "aws_availability_zones" "available"  {
      + id       = (known after apply)
      + names    = (known after apply)
      + state    = "available"
      + zone_ids = (known after apply)
    }

  # module.eks_cluster.aws_eks_cluster.remessa_cluster will be created
  + resource "aws_eks_cluster" "remessa_cluster" {
      + arn                       = (known after apply)
      + certificate_authority     = (known after apply)
      + created_at                = (known after apply)
      + enabled_cluster_log_types = [
          + "api",
          + "audit",
          + "authenticator",
          + "controllerManager",
          + "scheduler",
        ]
      + endpoint                  = (known after apply)
      + id                        = (known after apply)
      + identity                  = (known after apply)
      + name                      = "remessa-cluster-challenge"
      + platform_version          = (known after apply)
      + role_arn                  = (known after apply)
      + status                    = (known after apply)
      + version                   = "1.18"

      + vpc_config {
          + cluster_security_group_id = (known after apply)
          + endpoint_private_access   = true
          + endpoint_public_access    = true
          + public_access_cidrs       = (known after apply)
          + security_group_ids        = (known after apply)
          + subnet_ids                = (known after apply)
          + vpc_id                    = (known after apply)
        }
    }

  # module.eks_cluster.aws_eks_node_group.remessa_node_group_t3_large will be created
  + resource "aws_eks_node_group" "remessa_node_group_t3_large" {
      + ami_type        = (known after apply)
      + arn             = (known after apply)
      + cluster_name    = "remessa-cluster-challenge"
      + disk_size       = (known after apply)
      + id              = (known after apply)
      + instance_types  = [
          + "t3.large",
        ]
      + node_group_name = "remessa-node-group-t3-large-challenge"
      + node_role_arn   = (known after apply)
      + release_version = (known after apply)
      + resources       = (known after apply)
      + status          = (known after apply)
      + subnet_ids      = (known after apply)
      + tags            = {
          + "Name" = "EKS challenge Node Group"
        }
      + version         = (known after apply)

      + remote_access {
          + ec2_ssh_key               = "remessa"
          + source_security_group_ids = (known after apply)
        }

      + scaling_config {
          + desired_size = 1
          + max_size     = 10
          + min_size     = 1
        }
    }

  # module.eks_cluster.aws_iam_role.eks_cluster_admin_role will be created
  + resource "aws_iam_role" "eks_cluster_admin_role" {
      + arn                   = (known after apply)
      + assume_role_policy    = jsonencode(
            {
              + Statement = [
                  + {
                      + Action    = "sts:AssumeRole"
                      + Effect    = "Allow"
                      + Principal = {
                          + Service = "eks.amazonaws.com"
                        }
                    },
                ]
              + Version   = "2012-10-17"
            }
        )
      + create_date           = (known after apply)
      + description           = "Allows EKS to manage clusters on your behalf."
      + force_detach_policies = false
      + id                    = (known after apply)
      + max_session_duration  = 3600
      + name                  = "eks-admin-challenge"
      + path                  = "/"
      + unique_id             = (known after apply)
    }

  # module.eks_cluster.aws_iam_role.eks_cluster_node_admin_role will be created
  + resource "aws_iam_role" "eks_cluster_node_admin_role" {
      + arn                   = (known after apply)
      + assume_role_policy    = jsonencode(
            {
              + Statement = [
                  + {
                      + Action    = "sts:AssumeRole"
                      + Effect    = "Allow"
                      + Principal = {
                          + Service = "ec2.amazonaws.com"
                        }
                    },
                ]
              + Version   = "2012-10-17"
            }
        )
      + create_date           = (known after apply)
      + force_detach_policies = false
      + id                    = (known after apply)
      + max_session_duration  = 3600
      + name                  = "eks-node-group-role"
      + path                  = "/"
      + unique_id             = (known after apply)
    }

  # module.eks_cluster.aws_iam_role_policy_attachment.Remessa-AmazonEC2ContainerRegistryReadOnly will be created
  + resource "aws_iam_role_policy_attachment" "Remessa-AmazonEC2ContainerRegistryReadOnly" {
      + id         = (known after apply)
      + policy_arn = "arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly"
      + role       = "eks-node-group-role"
    }

  # module.eks_cluster.aws_iam_role_policy_attachment.Remessa-AmazonEC2FullAccess will be created
  + resource "aws_iam_role_policy_attachment" "Remessa-AmazonEC2FullAccess" {
      + id         = (known after apply)
      + policy_arn = "arn:aws:iam::aws:policy/AmazonEC2FullAccess"
      + role       = "eks-node-group-role"
    }

  # module.eks_cluster.aws_iam_role_policy_attachment.Remessa-AmazonEKSWorkerNodePolicy will be created
  + resource "aws_iam_role_policy_attachment" "Remessa-AmazonEKSWorkerNodePolicy" {
      + id         = (known after apply)
      + policy_arn = "arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy"
      + role       = "eks-node-group-role"
    }

  # module.eks_cluster.aws_iam_role_policy_attachment.Remessa-AmazonEKS_CNI_Policy will be created
  + resource "aws_iam_role_policy_attachment" "Remessa-AmazonEKS_CNI_Policy" {
      + id         = (known after apply)
      + policy_arn = "arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy"
      + role       = "eks-node-group-role"
    }

  # module.eks_cluster.aws_iam_role_policy_attachment.eks_cluster_policy will be created
  + resource "aws_iam_role_policy_attachment" "eks_cluster_policy" {
      + id         = (known after apply)
      + policy_arn = "arn:aws:iam::aws:policy/AmazonEKSClusterPolicy"
      + role       = "eks-admin-challenge"
    }

  # module.eks_cluster.aws_iam_role_policy_attachment.eks_cluster_service_policy will be created
  + resource "aws_iam_role_policy_attachment" "eks_cluster_service_policy" {
      + id         = (known after apply)
      + policy_arn = "arn:aws:iam::aws:policy/AmazonEKSServicePolicy"
      + role       = "eks-admin-challenge"
    }

  # module.eks_cluster.aws_network_acl.private will be created
  + resource "aws_network_acl" "private" {
      + arn        = (known after apply)
      + egress     = [
          + {
              + action          = "allow"
              + cidr_block      = "0.0.0.0/0"
              + from_port       = 0
              + icmp_code       = null
              + icmp_type       = null
              + ipv6_cidr_block = ""
              + protocol        = "-1"
              + rule_no         = 100
              + to_port         = 0
            },
        ]
      + id         = (known after apply)
      + ingress    = [
          + {
              + action          = "allow"
              + cidr_block      = "0.0.0.0/0"
              + from_port       = 0
              + icmp_code       = null
              + icmp_type       = null
              + ipv6_cidr_block = ""
              + protocol        = "-1"
              + rule_no         = 100
              + to_port         = 0
            },
        ]
      + owner_id   = (known after apply)
      + subnet_ids = (known after apply)
      + vpc_id     = (known after apply)
    }

  # module.eks_cluster.aws_route_table.private[0] will be created
  + resource "aws_route_table" "private" {
      + id               = (known after apply)
      + owner_id         = (known after apply)
      + propagating_vgws = (known after apply)
      + route            = [
          + {
              + cidr_block                = "0.0.0.0/0"
              + egress_only_gateway_id    = ""
              + gateway_id                = (known after apply)
              + instance_id               = ""
              + ipv6_cidr_block           = ""
              + nat_gateway_id            = ""
              + network_interface_id      = ""
              + transit_gateway_id        = ""
              + vpc_peering_connection_id = ""
            },
        ]
      + tags             = {
          + "AZ"   = "us-east-1a"
          + "Name" = "remessa-eks-private-route-table-challenge-us-east-1a"
          + "Type" = "Private"
        }
      + vpc_id           = (known after apply)
    }

  # module.eks_cluster.aws_route_table.private[1] will be created
  + resource "aws_route_table" "private" {
      + id               = (known after apply)
      + owner_id         = (known after apply)
      + propagating_vgws = (known after apply)
      + route            = [
          + {
              + cidr_block                = "0.0.0.0/0"
              + egress_only_gateway_id    = ""
              + gateway_id                = (known after apply)
              + instance_id               = ""
              + ipv6_cidr_block           = ""
              + nat_gateway_id            = ""
              + network_interface_id      = ""
              + transit_gateway_id        = ""
              + vpc_peering_connection_id = ""
            },
        ]
      + tags             = {
          + "AZ"   = "us-east-1b"
          + "Name" = "remessa-eks-private-route-table-challenge-us-east-1b"
          + "Type" = "Private"
        }
      + vpc_id           = (known after apply)
    }

  # module.eks_cluster.aws_route_table.private[2] will be created
  + resource "aws_route_table" "private" {
      + id               = (known after apply)
      + owner_id         = (known after apply)
      + propagating_vgws = (known after apply)
      + route            = [
          + {
              + cidr_block                = "0.0.0.0/0"
              + egress_only_gateway_id    = ""
              + gateway_id                = (known after apply)
              + instance_id               = ""
              + ipv6_cidr_block           = ""
              + nat_gateway_id            = ""
              + network_interface_id      = ""
              + transit_gateway_id        = ""
              + vpc_peering_connection_id = ""
            },
        ]
      + tags             = {
          + "AZ"   = "us-east-1c"
          + "Name" = "remessa-eks-private-route-table-challenge-us-east-1c"
          + "Type" = "Private"
        }
      + vpc_id           = (known after apply)
    }

  # module.eks_cluster.aws_route_table_association.public[0] will be created
  + resource "aws_route_table_association" "public" {
      + id             = (known after apply)
      + route_table_id = (known after apply)
      + subnet_id      = (known after apply)
    }

  # module.eks_cluster.aws_route_table_association.public[1] will be created
  + resource "aws_route_table_association" "public" {
      + id             = (known after apply)
      + route_table_id = (known after apply)
      + subnet_id      = (known after apply)
    }

  # module.eks_cluster.aws_route_table_association.public[2] will be created
  + resource "aws_route_table_association" "public" {
      + id             = (known after apply)
      + route_table_id = (known after apply)
      + subnet_id      = (known after apply)
    }

  # module.eks_cluster.aws_security_group.remessa_cluster will be created
  + resource "aws_security_group" "remessa_cluster" {
      + arn                    = (known after apply)
      + description            = "EKS created security group applied to ENI that is attached to EKS Control Plane master nodes, as well as any managed workloads."
      + egress                 = (known after apply)
      + id                     = (known after apply)
      + ingress                = (known after apply)
      + name                   = "eks-remessa-cluster-challenge"
      + owner_id               = (known after apply)
      + revoke_rules_on_delete = false
      + tags                   = {
          + "Name" = "security-group-eks-remessa-cluster-challenge"
        }
      + vpc_id                 = (known after apply)
    }

  # module.eks_cluster.aws_security_group.remessa_nodes will be created
  + resource "aws_security_group" "remessa_nodes" {
      + arn                    = (known after apply)
      + description            = "Security group for all nodes in the nodeGroup to allow SSH access"
      + egress                 = [
          + {
              + cidr_blocks      = [
                  + "0.0.0.0/0",
                ]
              + description      = ""
              + from_port        = 0
              + ipv6_cidr_blocks = []
              + prefix_list_ids  = []
              + protocol         = "-1"
              + security_groups  = []
              + self             = false
              + to_port          = 0
            },
        ]
      + id                     = (known after apply)
      + ingress                = (known after apply)
      + name                   = "security-group-node-group-eks-challenge"
      + owner_id               = (known after apply)
      + revoke_rules_on_delete = false
      + tags                   = {
          + "eks"                = "remessa_cluster_node_group"
          + "eks:nodegroup-name" = "remessa_cluster_node_group"
        }
      + vpc_id                 = (known after apply)
    }

  # module.eks_cluster.aws_security_group_rule.cluster_inbound will be created
  + resource "aws_security_group_rule" "cluster_inbound" {
      + description              = "Allow worker nodes to communicate with the cluster API Server"
      + from_port                = 443
      + id                       = (known after apply)
      + protocol                 = "tcp"
      + security_group_id        = (known after apply)
      + self                     = false
      + source_security_group_id = (known after apply)
      + to_port                  = 443
      + type                     = "ingress"
    }

  # module.eks_cluster.aws_security_group_rule.cluster_outbound will be created
  + resource "aws_security_group_rule" "cluster_outbound" {
      + description              = "Allow cluster API Server to communicate with the worker nodes"
      + from_port                = 1024
      + id                       = (known after apply)
      + protocol                 = "tcp"
      + security_group_id        = (known after apply)
      + self                     = false
      + source_security_group_id = (known after apply)
      + to_port                  = 65535
      + type                     = "egress"
    }

  # module.eks_cluster.aws_security_group_rule.nodes will be created
  + resource "aws_security_group_rule" "nodes" {
      + description              = "Allow nodes to communicate with each other"
      + from_port                = 0
      + id                       = (known after apply)
      + protocol                 = "-1"
      + security_group_id        = (known after apply)
      + self                     = false
      + source_security_group_id = (known after apply)
      + to_port                  = 65535
      + type                     = "ingress"
    }

  # module.eks_cluster.aws_security_group_rule.nodes_inbound will be created
  + resource "aws_security_group_rule" "nodes_inbound" {
      + description              = "Allow worker Kubelets and pods to receive communication from the cluster control plane"
      + from_port                = 1025
      + id                       = (known after apply)
      + protocol                 = "tcp"
      + security_group_id        = (known after apply)
      + self                     = false
      + source_security_group_id = (known after apply)
      + to_port                  = 65535
      + type                     = "ingress"
    }

  # module.eks_cluster.aws_subnet.eks[0] will be created
  + resource "aws_subnet" "eks" {
      + arn                             = (known after apply)
      + assign_ipv6_address_on_creation = false
      + availability_zone               = (known after apply)
      + availability_zone_id            = (known after apply)
      + cidr_block                      = "10.0.1.128/25"
      + id                              = (known after apply)
      + ipv6_cidr_block                 = (known after apply)
      + ipv6_cidr_block_association_id  = (known after apply)
      + map_public_ip_on_launch         = true
      + owner_id                        = (known after apply)
      + tags                            = {
          + "kubernetes.io/cluster/remessa-cluster-challenge" = "shared"
        }
      + vpc_id                          = (known after apply)
    }

  # module.eks_cluster.aws_subnet.eks[1] will be created
  + resource "aws_subnet" "eks" {
      + arn                             = (known after apply)
      + assign_ipv6_address_on_creation = false
      + availability_zone               = (known after apply)
      + availability_zone_id            = (known after apply)
      + cidr_block                      = "10.0.2.0/25"
      + id                              = (known after apply)
      + ipv6_cidr_block                 = (known after apply)
      + ipv6_cidr_block_association_id  = (known after apply)
      + map_public_ip_on_launch         = true
      + owner_id                        = (known after apply)
      + tags                            = {
          + "kubernetes.io/cluster/remessa-cluster-challenge" = "shared"
        }
      + vpc_id                          = (known after apply)
    }

  # module.eks_cluster.aws_subnet.eks[2] will be created
  + resource "aws_subnet" "eks" {
      + arn                             = (known after apply)
      + assign_ipv6_address_on_creation = false
      + availability_zone               = (known after apply)
      + availability_zone_id            = (known after apply)
      + cidr_block                      = "10.0.2.128/25"
      + id                              = (known after apply)
      + ipv6_cidr_block                 = (known after apply)
      + ipv6_cidr_block_association_id  = (known after apply)
      + map_public_ip_on_launch         = true
      + owner_id                        = (known after apply)
      + tags                            = {
          + "kubernetes.io/cluster/remessa-cluster-challenge" = "shared"
        }
      + vpc_id                          = (known after apply)
    }

  # module.vpc.aws_internet_gateway.remessa will be created
  + resource "aws_internet_gateway" "remessa" {
      + arn      = (known after apply)
      + id       = (known after apply)
      + owner_id = (known after apply)
      + vpc_id   = (known after apply)
    }

  # module.vpc.aws_vpc.remessa will be created
  + resource "aws_vpc" "remessa" {
      + arn                              = (known after apply)
      + assign_generated_ipv6_cidr_block = true
      + cidr_block                       = "10.0.0.0/16"
      + default_network_acl_id           = (known after apply)
      + default_route_table_id           = (known after apply)
      + default_security_group_id        = (known after apply)
      + dhcp_options_id                  = (known after apply)
      + enable_classiclink               = false
      + enable_classiclink_dns_support   = false
      + enable_dns_hostnames             = true
      + enable_dns_support               = true
      + id                               = (known after apply)
      + instance_tenancy                 = "default"
      + ipv6_association_id              = (known after apply)
      + ipv6_cidr_block                  = (known after apply)
      + main_route_table_id              = (known after apply)
      + owner_id                         = (known after apply)
      + tags                             = {
          + "Name" = "remessa-vpc-challenge"
        }
    }

Plan: 28 to add, 0 to change, 0 to destroy.


Warning: Interpolation-only expressions are deprecated

  on main.tf line 2, in locals:
   2:   public_cidr_block  = "${cidrsubnet("10.0.0.0/16", 1, 0)}"

Terraform 0.11 and earlier required all non-constant expressions to be
provided via interpolation syntax, but this pattern is now deprecated. To
silence this warning, remove the "${ sequence from the start and the }"
sequence from the end of this expression, leaving just the inner expression.

Template interpolation syntax is still used to construct strings from
expressions when the template includes multiple interpolation sequences or a
mixture of literal strings and interpolations. This deprecation applies only
to templates that consist entirely of a single interpolation sequence.

(and 4 more similar warnings elsewhere)


Warning: Version constraints inside provider configuration blocks are deprecated

  on providers.tf line 6, in provider "aws":
   6:   version = "~> 2.70.0"

Terraform 0.13 and earlier allowed provider version constraints inside the
provider configuration block, but that is now deprecated and will be removed
in a future version of Terraform. To silence this warning, move the provider
version constraint into the required_providers block.

Do you want to perform these actions in workspace "challenge"?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes

module.vpc.aws_vpc.remessa: Creating...
module.vpc.aws_vpc.remessa: Creation complete after 9s [id=vpc-0f41d4f4820784aea]
module.vpc.aws_internet_gateway.remessa: Creating...
module.vpc.aws_internet_gateway.remessa: Creation complete after 4s [id=igw-05115c4c1799e5770]
module.eks_cluster.data.aws_availability_zones.available: Reading...
module.eks_cluster.aws_security_group.remessa_cluster: Creating...
module.eks_cluster.aws_iam_role.eks_cluster_admin_role: Creating...
module.eks_cluster.aws_route_table.private[0]: Creating...
module.eks_cluster.aws_route_table.private[1]: Creating...
module.eks_cluster.aws_security_group.remessa_nodes: Creating...
module.eks_cluster.aws_route_table.private[2]: Creating...
module.eks_cluster.aws_iam_role.eks_cluster_node_admin_role: Creating...
module.eks_cluster.data.aws_availability_zones.available: Read complete after 1s [id=2020-12-18 23:50:42.175858 +0000 UTC]
module.eks_cluster.aws_subnet.eks[2]: Creating...
module.eks_cluster.aws_subnet.eks[1]: Creating...
module.eks_cluster.aws_subnet.eks[0]: Creating...
module.eks_cluster.aws_iam_role.eks_cluster_node_admin_role: Creation complete after 2s [id=eks-node-group-role]
module.eks_cluster.aws_iam_role.eks_cluster_admin_role: Creation complete after 2s [id=eks-admin-challenge]
module.eks_cluster.aws_iam_role_policy_attachment.Remessa-AmazonEC2FullAccess: Creating...
module.eks_cluster.aws_iam_role_policy_attachment.Remessa-AmazonEC2ContainerRegistryReadOnly: Creating...
module.eks_cluster.aws_iam_role_policy_attachment.Remessa-AmazonEC2FullAccess: Creation complete after 1s [id=eks-node-group-role-20201218235044566400000001]
module.eks_cluster.aws_iam_role_policy_attachment.Remessa-AmazonEC2ContainerRegistryReadOnly: Creation complete after 1s [id=eks-node-group-role-20201218235044633300000002]
module.eks_cluster.aws_iam_role_policy_attachment.Remessa-AmazonEKS_CNI_Policy: Creating...
module.eks_cluster.aws_iam_role_policy_attachment.Remessa-AmazonEKSWorkerNodePolicy: Creating...
module.eks_cluster.aws_route_table.private[1]: Creation complete after 4s [id=rtb-0c62afd7e45070039]
module.eks_cluster.aws_iam_role_policy_attachment.eks_cluster_policy: Creating...
module.eks_cluster.aws_route_table.private[0]: Creation complete after 4s [id=rtb-074c55a338f17c1c2]
module.eks_cluster.aws_iam_role_policy_attachment.eks_cluster_service_policy: Creating...
module.eks_cluster.aws_route_table.private[2]: Creation complete after 4s [id=rtb-0852e0a763b6be050]
module.eks_cluster.aws_subnet.eks[1]: Creation complete after 3s [id=subnet-0aabc79bb48cbdd14]
module.eks_cluster.aws_subnet.eks[2]: Creation complete after 4s [id=subnet-060b56244e3fb89aa]
module.eks_cluster.aws_iam_role_policy_attachment.eks_cluster_policy: Creation complete after 1s [id=eks-admin-challenge-20201218235046224400000004]
module.eks_cluster.aws_iam_role_policy_attachment.eks_cluster_service_policy: Creation complete after 1s [id=eks-admin-challenge-20201218235046220200000003]
module.eks_cluster.aws_iam_role_policy_attachment.Remessa-AmazonEKS_CNI_Policy: Creation complete after 2s [id=eks-node-group-role-20201218235046253400000005]
module.eks_cluster.aws_subnet.eks[0]: Creation complete after 4s [id=subnet-01980bfa7757efde5]
module.eks_cluster.aws_route_table_association.public[2]: Creating...
module.eks_cluster.aws_route_table_association.public[1]: Creating...
module.eks_cluster.aws_route_table_association.public[0]: Creating...
module.eks_cluster.aws_network_acl.private: Creating...
module.eks_cluster.aws_security_group.remessa_cluster: Creation complete after 6s [id=sg-0b2f26ecf1c326698]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Creating...
module.eks_cluster.aws_iam_role_policy_attachment.Remessa-AmazonEKSWorkerNodePolicy: Creation complete after 3s [id=eks-node-group-role-20201218235047282000000006]
module.eks_cluster.aws_route_table_association.public[2]: Creation complete after 0s [id=rtbassoc-023ebb31da503f2a5]
module.eks_cluster.aws_route_table_association.public[1]: Creation complete after 0s [id=rtbassoc-003ac61c1271122b1]
module.eks_cluster.aws_route_table_association.public[0]: Creation complete after 0s [id=rtbassoc-0412ce9c096d02331]
module.eks_cluster.aws_security_group.remessa_nodes: Creation complete after 6s [id=sg-0a78ad2553ee9a5ba]
module.eks_cluster.aws_security_group_rule.nodes: Creating...
module.eks_cluster.aws_security_group_rule.cluster_inbound: Creating...
module.eks_cluster.aws_security_group_rule.nodes_inbound: Creating...
module.eks_cluster.aws_security_group_rule.cluster_outbound: Creating...
module.eks_cluster.aws_security_group_rule.cluster_inbound: Creation complete after 3s [id=sgrule-3190010678]
module.eks_cluster.aws_security_group_rule.nodes: Creation complete after 3s [id=sgrule-1102454114]
module.eks_cluster.aws_security_group_rule.cluster_outbound: Creation complete after 5s [id=sgrule-549520832]
module.eks_cluster.aws_security_group_rule.nodes_inbound: Creation complete after 5s [id=sgrule-1717062900]
module.eks_cluster.aws_network_acl.private: Creation complete after 8s [id=acl-00d9860a4076b2234]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [10s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [20s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [30s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [40s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [50s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [1m0s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [1m10s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [1m20s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [1m30s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [1m40s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [1m50s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [2m0s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [2m10s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [2m20s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [2m30s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [2m40s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [2m50s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [3m0s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [3m10s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [3m20s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [3m30s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [3m40s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [3m50s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [4m0s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [4m10s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [4m20s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [4m30s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [4m40s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [4m50s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [5m0s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [5m10s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [5m20s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [5m30s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [5m40s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [5m50s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [6m0s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [6m10s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [6m20s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [6m30s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [6m40s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [6m50s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [7m0s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [7m10s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [7m20s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [7m30s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [7m40s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [7m50s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [8m0s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [8m10s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [8m20s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [8m30s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [8m40s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [8m50s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [9m0s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [9m10s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [9m20s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [9m30s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [9m40s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [9m50s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [10m0s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [10m10s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [10m20s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [10m30s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [10m40s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [10m50s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [11m0s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [11m10s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [11m20s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [11m30s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [11m40s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [11m50s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [12m0s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [12m10s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [12m20s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [12m30s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [12m40s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [12m50s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [13m0s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [13m10s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [13m20s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [13m30s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [13m40s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [13m50s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [14m0s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [14m10s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [14m20s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [14m30s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [14m40s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [14m50s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [15m0s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [15m10s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [15m20s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [15m30s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [15m40s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [15m50s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [16m0s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [16m10s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [16m20s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [16m30s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [16m40s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [16m50s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [17m0s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [17m10s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [17m20s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Still creating... [17m30s elapsed]
module.eks_cluster.aws_eks_cluster.remessa_cluster: Creation complete after 17m37s [id=remessa-cluster-challenge]
module.eks_cluster.aws_eks_node_group.remessa_node_group_t3_large: Creating...
module.eks_cluster.aws_eks_node_group.remessa_node_group_t3_large: Still creating... [10s elapsed]
module.eks_cluster.aws_eks_node_group.remessa_node_group_t3_large: Still creating... [20s elapsed]
module.eks_cluster.aws_eks_node_group.remessa_node_group_t3_large: Still creating... [30s elapsed]
module.eks_cluster.aws_eks_node_group.remessa_node_group_t3_large: Still creating... [40s elapsed]
module.eks_cluster.aws_eks_node_group.remessa_node_group_t3_large: Still creating... [50s elapsed]
module.eks_cluster.aws_eks_node_group.remessa_node_group_t3_large: Still creating... [1m0s elapsed]
module.eks_cluster.aws_eks_node_group.remessa_node_group_t3_large: Still creating... [1m10s elapsed]
module.eks_cluster.aws_eks_node_group.remessa_node_group_t3_large: Still creating... [1m20s elapsed]
module.eks_cluster.aws_eks_node_group.remessa_node_group_t3_large: Still creating... [1m30s elapsed]
module.eks_cluster.aws_eks_node_group.remessa_node_group_t3_large: Still creating... [1m40s elapsed]
module.eks_cluster.aws_eks_node_group.remessa_node_group_t3_large: Still creating... [1m50s elapsed]
module.eks_cluster.aws_eks_node_group.remessa_node_group_t3_large: Creation complete after 1m52s [id=remessa-cluster-challenge:remessa-node-group-t3-large-challenge]